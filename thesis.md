# 1. Introduzione

#### 1.1 Robot di servizio

I robot di servizio sono una tipologia di robot creata per assistere l'essere umano in ambienti antropocentrici, come abitazioni, uffici e ospedali, il tutto in maniera autonoma o semi-autonoma. L'obiettivo è semplificare la vita quotidiana delle persone, aumentando la sicurezza e la produttività.

Negli ultimi decenni questi robot si sono diffusi in vari settori, come quello logistico e sanitario, andando a supportare attività potenzialmente pericolose e soggette ad errori, come ad esempio il trasporto di carichi pesanti o la consegna di medicinali e materiale medico.

Il motivo della diffusione dei robot per questi specifici compiti risiede nel tipo di ambiente nel quale operano; un magazzino è un ambiente prevedibile, in quanto ogni robot mobile conosce lo stato e la posizione di ogni singolo prodotto sulle scaffalature, così come la posizione di ogni altro robot all'interno della struttura. La stessa cosa non si può invece dire nel caso di ambienti più complessi, come ad esempio quello domestico. In ogni abitazione caratteristiche come la planimetria e l'arredamento possono cambiare totalmente, oltre agli ostacoli presenti, siano essi mobili o fissi. A tutto questo si aggiungono anche i comportamenti imprevedibili di persone e animali, che possono interferire con le attività del robot [[1]](https://ieeexplore.ieee.org/abstract/document/6301139).

Un robot di servizio deve quindi riuscire a percepire e comprendere l'ambiente che lo circonda, così da poter svolgere compiti essenziali come la localizzazione, la navigazione e la pianificazione. Questo è possibile grazie a telecamere e sensori di profondità, che consentono di acquisire immagini e mappare lo spazio circostante, e a reti neurali che permettono di riconoscere e classificare oggetti. L'insieme di queste tecniche è comunemente chiamata robotic vision.

#### 1.2 Problema della raccolta dati

L'addestramento di reti neurali è uno dei processi più importanti nella creazione di un sistema di robotic vision, e il suo corretto funzionamento dipende da vari fattori come la scelta del modello e dal processo di raccolta dei dati.

Per quanto riguarda la selezione del modello, a seconda delle attività che il robot deve svolgere si preferiscono determinate tipologie di modelli ad altre. Ad esempio, se si vogliono riconoscere oggetti in tempo reale si preferiscono reti neurali di tipo convoluzionale [[2]](https://arxiv.org/abs/1511.08458) (CNN, Convolutional Neural Network), mentre se l'obiettivo è comprendere sequenze di azioni complesse, come nel caso dell'interazione con gli esseri umani, si opta in genere per reti neurali ricorrenti [[3]](https://www.sciencedirect.com/science/article/pii/S0007850620300998) (RNN, Recurrent Neural Network). La sfida più grande non è però la scelta del modello, quanto la raccolta dei dati utilizzata per l'addestramento.

Raccogliere dati è da sempre un processo complesso in qualsiasi ambito, ma trova maggiori difficoltà in progetti di robotic vision. In questi casi, infatti, i dati vengono generalmente acquisiti facendo interagire robot con ambienti del mondo reale. Questo approccio ha però diverse limitazioni, dovute a fattori come il tempo e i costi che la raccolta comporta, oltre che per motivi riguardanti la sicurezza di persone, animali e oggetti presenti nell'ambiente. A questi elementi si aggiunge anche il fattore riproducibilità, che viene meno quando si hanno variazioni nell'hardware utilizzato o negli ambienti considerati, e che può condurre a risultati differenti. 

#### 1.3 Addestramento con dati simulati

Una possibile soluzione a questi problemi è l'utilizzo di ambienti simulati per la raccolta di dati. Questo permette infatti di ottenere dati a basso costo, in quanto non è necessario impegnare veri ambienti e robot, in tempi più brevi, grazie al fatto che le simulazioni possono essere velocizzate o parallelizzate, e senza i possibili rischi che una reale interazione con l'ambiente comporta.

Un simulatore consente inoltre di conoscere in anticipo e progettare gli scenari in cui un robot andrà ad interagire, andando a regolare vari parametri così da controllarne ogni singolo aspetto. Questo garantisce che l'ambiente non vari ed evolva nel tempo, a meno che non sia stato appositamente programmato per farlo.

Questo approccio permette di risolvere molti problemi, ma ne introduce di nuovi. La simulazione è infatti solo un'approssimazione della realtà, e non è possibile replicare fedelmente tutti i fenomeni e le caratteristiche del mondo reale. I motivi per i quale queste tipologie di ambienti differiscono sono principalmente due: il fotorealismo e l'interazione fisica.

Per fotorealismo si intende la capacità del simulatore di riprodurre in maniera visivamente accurata ambienti reali, in modo dettagliato e credibile. Tuttavia, risulta difficile replicare fenomeni come l'illuminazione, le riflessioni e texture di superfici. Questa mancanza di dettaglii ha un grande impatto sulla qualità dei dati raccolti per l'addestramento, con una conseguente mancanza di generalizzazione nel mondo reale da parte del modello. 

L'interazione fisica si riferisce invece all'abilità del simulatore di riuscire a replicare le leggi della fisica in maniera realistica; questo comprende ad esempio il movimento e l'interazione tra oggetti. 

In questi ultimi anni sono stati sviluppati diversi nuovi simulatori [[4]](https://arxiv.org/abs/1712.05474) [[5]](https://proceedings.neurips.cc/paper/2021/hash/021bbc7ee20b71134d53e20206bd6feb-Abstract.html) [[6]](https://arxiv.org/abs/1908.01887) [[7]](https://ieeexplore.ieee.org/abstract/document/1389727), ognuno specializzato per specifici casi d'uso, e tutti si concentrano pervalentemente su uno dei due aspetti sopra citati.

Reti neurali addestrate con dati provenienti da simulatori e testati negli stessi ambienti simulati, otterranno risultati eccellenti. Sapranno infatti individuare e riconoscere correttamente gli oggetti presenti, in quanto il dominio dei dati utilizzato per l'addestramento e quello usato per il testing è lo stesso. Invece, l'adozione di reti naurali addestrare con dati sintetici in ambienti reali, avranno performance scadenti, non riuscendo neanche a riconoscere le categorie di oggetti più comuni presenti nel mondo reale [[8]](https://ieeexplore.ieee.org/abstract/document/8793591). Questo problema è noto come sim to real gap, letteralmente 'divario tra simulazione e realtà', e rappresenta la differenza di prestazioni tra un modello addestrato in un ambiente simulato, e le performance nel mondo reale.

Una soluzione che permette di mitigare questo problema è l'adozione di una tecnica chiamata domain randomization , che permette di variare caratteristiche ed oggetti presenti nell'ambiente simulato (posizione e tipi di oggetti, illuminazione, texture). Questo permette di rendere il modello più robusto, permettendogli di operare meglio in contesti reali.

# 2. Stato dell'arte

Il sim to real gap è uno dei principali problemi nel campo della robitic vision, in quanto la complessità degli ambienti reali va oltre quello che è possibile rappresentare attraverso una simulazione. In questi ultimi anni la comunità scientifica si è interessata a questo problema, e ha provato a proporre delle soluzioni.

#### 2.1 Domain adaptation

Quella del domain adaptation è una delle strategie più utilizzate per cercare di ridurre il sim to real gap, in quanto si cercano di ridurre le differenze tra l'ambiente simulato e quello reale. Questa tecnica si basa sul trasformare i dati provenienti dal simulatore, in modo da farli assomigliare il più possibile a quelli raccolti nel mondo reale. Il processo di trasformazione dei dati comprende l'utilizzo di tecnologie come le reti generative avversarie [[10]](https://dl.acm.org/doi/abs/10.1145/3422622) (GAN, Generative Adversarial Network), che utilizzano in genere due diverse reti neurali per migliorare la qualità dei dati simulati. Una rete crea nuove immagini, il più simili possibili a quelle reali, mentre l'altra valuta la bontà delle immagini generate, che devono essere il più realistiche possibili. Questo approccio si è rivelato particolarmente efficace e ha permesso di migliorare le performance di generalizzazione nei modelli di robotic vision [[11]](https://openaccess.thecvf.com/content_cvpr_2017/html/Shrivastava_Learning_From_Simulated_CVPR_2017_paper.html).

Ad esempio, un'immagine presa da un ambiente simulato, con texture uniformi e un'illuminazione predefinita, può essere trasformata in una più fotorealistica variando la luce, aggiungendo riflessioni, creando imperfezioni sulla superficie di oggetti. In pratica si cerca di aggiungere caratteristiche presenti nel mondo reale a dati campionati da simulatori, in modo da ridurre la differenza tra quello che è il dominio della simulazione e quello della realtà.

#### 2.2 Data augmentation

Un ulteriore approccio per ridurre il sim to real gap è quello di augmentare i dati reali disponibili durante il training. La data augmentation è una tecnica molto diffusa nel campo della robotic vision, e consiste nell'applicare trasformazioni a dataset reali con l'obiettivo di aumentare sia il numero di dati disponibili, che l'eterogeneità dei dati stessi [[12]](https://link.springer.com/article/10.1186/s40537-019-0197-0). Queste trasformazioni possono comprendere rotazioni, ridimensionamenti, traslazioni, e l'applicazione di filtri che possano simulare condizioni ambientali come nebbia, riflessi e occlusione ambientale. La data augmentation permette sia di aumentare la dimensione di dataset senza la necessità di campionare nuovi dati, sia consente ai modelli di generalizzare meglio a variazioni presenti nel mondo reale. Consideriamo ad esempio un robot che deve riuscire a riconoscere e classificare oggetti in ambienti con un'illuminazione dinamica; applicare filtri per simulare differenti condizioni di luce può migliorare significativamente le sue abilità di generalizzazione [[13]](https://proceedings.neurips.cc/paper/2021/hash/fb4c48608ce8825b558ccf07169a3421-Abstract.html). Inoltre, la data augmentation può essere usata in presenza di dataset sbilanciati, nei quali alcune classi sono sottorappresentate rispetto ad altre. Attraverso una serie di trasformazioni è infatti possibile aumentare il numero di dati appartenenti alle classi meno presenti, migliorando di conseguenta le capacità del modello nel riconoscerle.

Un'altro esempio nel quale questa tecnica può tornare utile, è nel caso si vengano a creare dipendenze da caretteristiche non rilevanti (bias). Ad esempio, se un modello tende ad associare la presenza di uno specifico sfondo a quella di un particolare oggetto, può essere conveniente effettuare trasformazioni andando a modificare o rimuovere lo sfondo, in modo da rendere indipendente la presenza di un oggetto da quella di un'altro.

Un esempio di bias è ben descritto nell'articolo [[14]](https://www.mdpi.com/2075-4418/12/1/40), relativo ad un modello addestrato a riconoscere melanomi da tessuti sani. La rete neurale è stata addestrata a partire da un dataset contenente foto raffiguranti tumori maligni e tessuti epiteliali sani. Sebbene i risultati di validazione fossero inizialmente promettenti, si è scoperto che il modello non aveva realmente imparato a riconoscere la presenza di melanomi. Piuttosto, basava le sue previsioni su correlazioni spurie presenti nei dati. Nelle immagini raffiguranti tessuti sani erano sempre presenti artefatti come righelli e altri strumenti di calibrazione, che erano invece assenti in quelle rappresentanti tumori maligni. Come conseguenza, questi dati hanno portato il modello a trovare delle "scorciatoie" (shortcut learning), utilizzando la presenza di questi artefatti come principale regola per classificare le immagini.

#### 2.3 Domain randomization

Invece che addestrare un modello su una singola scena simulata creata manualmente, la domain randomization permette di randomizzare gli elementi come oggetti, luce, texture ed eventuale rumore in maniera automatica all'interno di uno stesso ambiente. Questo consente al modello di imparare molteplici dispozizioni di oggetti e caratteristiche, migliorandone così le capacità di generalizzazione. Con questo approccio si cercano quindi di ricreare le condizioni che caratterizzano un normale ambiente domestico; a distanza di pochi giorni è raro che vengano introdotti o rimossi degli oggetti, mentre è molto più probabile che oggetti già presenti vengano spostati. Questo comporta una diversa disposizione degli oggetti, con una conseguente differenza nell'illuminazione della stanza, nei riflessi, e possibilmente anche nei colori. Se il modello non è abbastanza robusto a questo tipo di cambiamenti, potrebbe non riuscire a generalizzare correttamente.

Questa tecnica [[15]](https://ieeexplore.ieee.org/abstract/document/8202133) è particolarmente efficace nell'addestrare reti neurali profonde (DNN, Deep Neural Netework) per compiti come l'identificazione e la manipolazione di oggetti. Ha infatti permesso di addestrare un modello utilizzando solo immagini simulate, riuscendo poi a localizzare in maniera accurata oggetti in ambienti reali, senza necessitare di ulteriori dati provenienti dal mondo reale.

La domain randomization permette quindi di generare grandi dataset di addestramento col minimo sforzo da parte di un operatore umano, e di ottenere modelli robusti senza la necessità di effettuare fine tuning con dati reali.
